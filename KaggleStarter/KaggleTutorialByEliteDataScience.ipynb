{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning Tutorial, Scikit-Learn: Wine Snob Edition\n",
    "[Tips for kaggle](https://elitedatascience.com/beginner-kaggle)\n",
    "\n",
    "This tutorial is based on \n",
    "[python tutorials](https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn) from elite Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "# check the Sckit-Learn version\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Import libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy efficient numerical computation\n",
    "import numpy as np\n",
    "# handle numerical matrices\n",
    "import pandas as pd\n",
    "# many utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "# entire preprocessing module including scaling, transforming, and wrangling data\n",
    "from sklearn import preprocessing\n",
    "# import the random forest family\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# import performing cross-validation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# import module for saving scikit-learn module\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load red wine data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to load datasets.\n",
    "[list of all the Pandas IO tools](http://pandas.pydata.org/pandas-docs/stable/io.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wine data from remote URL\n",
    "dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"\n",
      "0   7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5                                                                                                                     \n",
      "1   7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5                                                                                                                     \n",
      "2  7.8;0.76;0.04;2.3;0.092;15;54;0.997;3.26;0.65;...                                                                                                                     \n",
      "3  11.2;0.28;0.56;1.9;0.075;17;60;0.998;3.16;0.58...                                                                                                                     \n",
      "4   7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5                                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "# output the first 5 rows of data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV file separate data by semicolons, so we should use semicolon separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Read CSV with semicolon seperator\n",
    "data = pd.read_csv(dataset_url, sep=';')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n",
      "Sample size is 1599\n",
      "feature size is 12\n"
     ]
    }
   ],
   "source": [
    "# print shape of data\n",
    "print(data.shape)\n",
    "# samples\n",
    "print('Sample size is', data.shape[0])\n",
    "# features\n",
    "print('feature size is', data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
      "mean        8.319637          0.527821     0.270976        2.538806   \n",
      "std         1.741096          0.179060     0.194801        1.409928   \n",
      "min         4.600000          0.120000     0.000000        0.900000   \n",
      "25%         7.100000          0.390000     0.090000        1.900000   \n",
      "50%         7.900000          0.520000     0.260000        2.200000   \n",
      "75%         9.200000          0.640000     0.420000        2.600000   \n",
      "max        15.900000          1.580000     1.000000       15.500000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
      "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
      "mean      0.087467            15.874922             46.467792     0.996747   \n",
      "std       0.047065            10.460157             32.895324     0.001887   \n",
      "min       0.012000             1.000000              6.000000     0.990070   \n",
      "25%       0.070000             7.000000             22.000000     0.995600   \n",
      "50%       0.079000            14.000000             38.000000     0.996750   \n",
      "75%       0.090000            21.000000             62.000000     0.997835   \n",
      "max       0.611000            72.000000            289.000000     1.003690   \n",
      "\n",
      "                pH    sulphates      alcohol      quality  \n",
      "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
      "mean      3.311113     0.658149    10.422983     5.636023  \n",
      "std       0.154386     0.169507     1.065668     0.807569  \n",
      "min       2.740000     0.330000     8.400000     3.000000  \n",
      "25%       3.210000     0.550000     9.500000     5.000000  \n",
      "50%       3.310000     0.620000    10.200000     6.000000  \n",
      "75%       3.400000     0.730000    11.100000     6.000000  \n",
      "max       4.010000     2.000000    14.900000     8.000000  \n"
     ]
    }
   ],
   "source": [
    "# Lets summarize statistics\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Split data into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and test sets at the beginning of your modeling workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target from training features\n",
    "y = data.quality\n",
    "X = data.drop('quality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Declare data preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.51358886  2.19680282 -0.164433   ...,  1.08415147 -0.69866131\n",
      "  -0.58608178]\n",
      " [-1.73698885 -0.31792985 -0.82867679 ...,  1.46964764  1.2491516\n",
      "   2.97009781]\n",
      " [-0.35201795  0.46443143 -0.47100705 ..., -0.13658641 -0.35492962\n",
      "  -0.20843439]\n",
      " ..., \n",
      " [-0.98679628  1.10708533 -0.93086814 ...,  0.24890976 -0.98510439\n",
      "   0.35803669]\n",
      " [-0.69826067  0.46443143 -1.28853787 ...,  1.08415147 -0.35492962\n",
      "  -0.68049363]\n",
      " [ 3.1104093  -0.62528606  2.08377675 ..., -1.61432173  0.79084268\n",
      "  -0.39725809]]\n"
     ]
    }
   ],
   "source": [
    "# Lazy way of scaling data\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "print(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of each axis in train data\n",
      "[  1.16664562e-16  -3.05550043e-17  -8.47206937e-17  -2.22218213e-17\n",
      "   2.22218213e-17  -6.38877362e-17  -4.16659149e-18  -2.54439854e-15\n",
      "  -8.70817622e-16  -4.08325966e-16  -1.17220107e-15]\n",
      "Standard deviation of each axis in train data\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print('Average of each axis in train data')\n",
    "print(X_train_scaled.mean(axis=0)) \n",
    "\n",
    "print('Standard deviation of each axis in train data')\n",
    "print(X_train_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fit the transformer on the training set (saving the means and standard deviations)\n",
    "## 2. Apply the transformer to the training set (scaling the training data)\n",
    "## 3. Apply the transformer to the test set (using the same means and standard deviations)\n",
    "## 4. Allow to insert your preprocessing steps into a cross-validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Transformer API\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying transformer to training data\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average\n",
      "[  1.16664562e-16  -3.05550043e-17  -8.47206937e-17  -2.22218213e-17\n",
      "   2.22218213e-17  -6.38877362e-17  -4.16659149e-18  -2.54439854e-15\n",
      "  -8.70817622e-16  -4.08325966e-16  -1.17220107e-15]\n",
      "Standard deviation\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print('Average')\n",
    "print(X_train_scaled.mean(axis=0))\n",
    "print('Standard deviation')\n",
    "print(X_train_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applyin transformer to test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average\n",
      "[ 0.02776704  0.02592492 -0.03078587 -0.03137977 -0.00471876 -0.04413827\n",
      " -0.02414174 -0.00293273 -0.00467444 -0.10894663  0.01043391]\n",
      "Standard deviation\n",
      "[ 1.02160495  1.00135689  0.97456598  0.91099054  0.86716698  0.94193125\n",
      "  1.03673213  1.03145119  0.95734849  0.83829505  1.0286218 ]\n"
     ]
    }
   ],
   "source": [
    "print('Average')\n",
    "print(X_test_scaled.mean(axis=0))\n",
    "print('Standard deviation')\n",
    "print(X_test_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline with prerprocessing and model\n",
    "# modeling pipeline\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Declare hyperparameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'steps': [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False))], 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'randomforestregressor': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False), 'standardscaler__copy': True, 'standardscaler__with_mean': True, 'standardscaler__with_std': True, 'randomforestregressor__bootstrap': True, 'randomforestregressor__criterion': 'mse', 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__max_leaf_nodes': None, 'randomforestregressor__min_impurity_split': 1e-07, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__min_weight_fraction_leaf': 0.0, 'randomforestregressor__n_estimators': 100, 'randomforestregressor__n_jobs': 1, 'randomforestregressor__oob_score': False, 'randomforestregressor__random_state': None, 'randomforestregressor__verbose': 0, 'randomforestregressor__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# List tunable hyperparameters\n",
    "print(pipeline.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  declare the hyperparameters we want to tune through cross-validation\n",
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Tune model using a cross-validation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation (CV) pipeline looks like\n",
    "- 1 Split your data into k equal parts, or \"folds\" (typically k=10).\n",
    "- 2 Preprocess k-1 training folds.\n",
    "- 3 Train your model on the same k-1 folds.\n",
    "- 4 Preprocess the hold-out fold using the same transformations from step (2).\n",
    "- 5 Evaluate your model on the same hold-out fold.\n",
    "- 6 Perform steps (2) - (5) k times, each time holding out a different fold.\n",
    "- 7 Aggregate the performance across all k folds. This is your performance metric.\n",
    "You can use GridSearchCV which essentially performs CV for entire grid of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'randomforestregressor__max_features': ['auto', 'sqrt', 'log2'], 'randomforestregressor__max_depth': [None, 5, 3, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn cross-validation with pipeline\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
    " # Fit and tune model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "# print best parameters\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Refit on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Confirm model will be retrained.\n",
    "print(clf.refit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Evaluate model pipeline on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict a new set of data (test data)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.466173012894\n",
      "0.344464375\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "print(r2_score(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Save model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_regressor.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model to a .pkl file\n",
    "joblib.dump(clf, 'rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.44,  5.79,  4.99,  5.37,  6.29,  5.59,  4.91,  4.83,  5.02,\n",
       "        5.93,  5.39,  5.7 ,  5.78,  5.06,  5.78,  5.7 ,  6.59,  5.8 ,\n",
       "        5.64,  6.96,  5.39,  5.64,  5.02,  6.03,  6.  ,  5.02,  5.48,\n",
       "        5.15,  5.83,  5.96,  5.86,  6.6 ,  5.98,  5.06,  5.01,  5.89,\n",
       "        5.1 ,  6.08,  5.07,  5.91,  4.96,  6.05,  6.7 ,  5.13,  6.13,\n",
       "        5.49,  5.51,  5.6 ,  5.11,  6.49,  6.08,  5.22,  5.89,  5.05,\n",
       "        5.56,  5.75,  5.31,  5.33,  4.99,  5.3 ,  5.21,  5.21,  5.04,\n",
       "        5.77,  5.97,  5.16,  6.54,  5.  ,  5.21,  6.79,  5.72,  5.81,\n",
       "        5.08,  5.06,  5.32,  6.03,  5.38,  5.11,  5.23,  5.21,  6.37,\n",
       "        5.76,  6.16,  6.31,  5.06,  5.91,  6.38,  6.45,  5.75,  5.77,\n",
       "        5.94,  5.28,  6.4 ,  5.69,  5.67,  5.78,  6.67,  6.84,  5.6 ,\n",
       "        6.7 ,  5.12,  5.47,  5.1 ,  6.59,  5.06,  4.79,  5.7 ,  4.89,\n",
       "        5.55,  5.9 ,  5.81,  5.48,  5.94,  5.43,  5.24,  5.21,  5.98,\n",
       "        5.14,  4.92,  5.9 ,  5.75,  5.06,  5.73,  6.1 ,  5.21,  5.43,\n",
       "        5.22,  6.05,  5.44,  5.4 ,  5.77,  6.31,  5.25,  5.15,  5.06,\n",
       "        6.35,  5.04,  5.23,  6.72,  5.49,  5.19,  5.08,  5.67,  6.02,\n",
       "        5.35,  5.38,  5.18,  6.6 ,  5.78,  5.13,  5.61,  5.23,  5.  ,\n",
       "        5.08,  5.19,  5.91,  5.36,  5.81,  5.64,  5.38,  5.58,  5.31,\n",
       "        5.25,  5.89,  5.08,  5.86,  5.12,  5.48,  5.74,  5.19,  5.9 ,\n",
       "        5.08,  5.63,  5.04,  5.5 ,  5.48,  5.09,  5.64,  5.68,  5.07,\n",
       "        6.05,  5.47,  5.04,  4.99,  5.24,  6.12,  5.21,  5.62,  5.2 ,\n",
       "        4.99,  5.51,  6.56,  5.78,  5.91,  5.44,  5.14,  5.46,  5.13,\n",
       "        6.28,  4.83,  6.37,  5.06,  5.26,  5.27,  6.8 ,  5.99,  5.28,\n",
       "        5.17,  5.2 ,  6.02,  5.78,  5.97,  5.92,  6.18,  5.83,  5.97,\n",
       "        5.21,  5.25,  5.68,  5.27,  5.25,  5.85,  6.12,  5.63,  5.83,\n",
       "        5.91,  5.51,  6.17,  5.46,  5.77,  5.39,  5.53,  6.24,  5.68,\n",
       "        4.9 ,  4.53,  6.64,  6.52,  6.31,  5.35,  5.42,  5.53,  5.41,\n",
       "        6.3 ,  6.06,  5.19,  5.22,  5.16,  5.24,  6.38,  5.21,  5.04,\n",
       "        5.27,  5.2 ,  5.96,  6.39,  5.63,  5.31,  5.51,  6.46,  5.5 ,\n",
       "        6.01,  5.28,  5.24,  5.65,  5.86,  5.72,  5.55,  5.37,  5.07,\n",
       "        5.77,  5.56,  6.51,  6.18,  5.65,  5.06,  6.  ,  6.51,  6.  ,\n",
       "        5.49,  5.63,  5.34,  5.31,  5.96,  6.9 ,  5.26,  6.41,  5.93,\n",
       "        5.4 ,  5.53,  5.58,  5.18,  5.27,  6.2 ,  5.73,  5.98,  5.94,\n",
       "        5.93,  5.38,  5.69,  5.68,  6.12,  5.47,  6.85,  6.82,  5.87,\n",
       "        6.42,  5.02,  5.21,  5.89,  5.29,  5.37,  6.01,  6.64,  6.32,\n",
       "        5.27,  5.55,  5.68,  5.99,  5.5 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model from .pkl file\n",
    "clf2 = joblib.load('rf_regressor.pkl')\n",
    "# Predict data set using loaded model\n",
    "clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
